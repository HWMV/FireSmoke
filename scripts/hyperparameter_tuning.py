#!/usr/bin/env python3
"""
í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ìë™ìœ¼ë¡œ ì‹¤í—˜í•˜ì—¬ ìµœì  ì„¤ì •ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import os
import sys
import yaml
import argparse
import itertools
import subprocess
import time
from pathlib import Path
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class HyperparameterTuner:
    def __init__(self, base_config_path, output_dir='experiments'):
        self.base_config_path = base_config_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
        with open(base_config_path, 'r') as f:
            self.base_config = yaml.safe_load(f)
        
        # ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš©
        self.results = []
        
    def create_experiment_config(self, params, experiment_name):
        """ì‹¤í—˜ìš© ì„¤ì • íŒŒì¼ ìƒì„±"""
        config = self.base_config.copy()
        
        # íŒŒë¼ë¯¸í„° ì ìš©
        for key_path, value in params.items():
            keys = key_path.split('.')
            current = config
            for key in keys[:-1]:
                if key not in current:
                    current[key] = {}
                current = current[key]
            current[keys[-1]] = value
        
        # ì‹¤í—˜ ì´ë¦„ ì„¤ì •
        config['experiment_name'] = experiment_name
        
        # WandB ì„¤ì • (ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸°)
        if 'wandb' in config:
            config['wandb']['group'] = f"tuning_{datetime.now().strftime('%Y%m%d_%H%M')}"
            config['wandb']['name'] = experiment_name
        
        # ì„¤ì • íŒŒì¼ ì €ì¥
        config_path = self.output_dir / f"{experiment_name}.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        return config_path
    
    def run_experiment(self, config_path, experiment_name):
        """ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰"""
        print(f"\nğŸš€ ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        print(f"ì„¤ì • íŒŒì¼: {config_path}")
        
        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        cmd = [
            'python', 'scripts/train/train.py',
            '--config', str(config_path)
        ]
        
        start_time = time.time()
        
        try:
            # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            log_file = self.output_dir / f"{experiment_name}.log"
            
            with open(log_file, 'w') as f:
                process = subprocess.run(
                    cmd,
                    stdout=f,
                    stderr=subprocess.STDOUT,
                    text=True,
                    timeout=7200  # 2ì‹œê°„ íƒ€ì„ì•„ì›ƒ
                )
            
            success = process.returncode == 0
            runtime = time.time() - start_time
            
            if success:
                print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_name} ({runtime:.1f}ì´ˆ)")
            else:
                print(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {experiment_name}")
            
            return success, runtime
            
        except subprocess.TimeoutExpired:
            print(f"â° ì‹¤í—˜ íƒ€ì„ì•„ì›ƒ: {experiment_name}")
            return False, time.time() - start_time
        except Exception as e:
            print(f"âŒ ì‹¤í—˜ ì˜¤ë¥˜: {experiment_name} - {e}")
            return False, time.time() - start_time
    
    def extract_results(self, experiment_name):
        """ì‹¤í—˜ ê²°ê³¼ ì¶”ì¶œ"""
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìµœê³  ì„±ëŠ¥ í™•ì¸
        checkpoint_dir = Path('outputs/checkpoints')
        best_checkpoint = checkpoint_dir / 'best.pth'
        
        if best_checkpoint.exists():
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ
            try:
                import torch
                checkpoint = torch.load(best_checkpoint, map_location='cpu')
                best_loss = checkpoint.get('best_loss', float('inf'))
                epoch = checkpoint.get('epoch', 0)
                
                return {
                    'best_loss': float(best_loss),
                    'epochs_trained': int(epoch),
                    'checkpoint_exists': True
                }
            except Exception as e:
                print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {
                    'best_loss': float('inf'),
                    'epochs_trained': 0,
                    'checkpoint_exists': False
                }
        else:
            return {
                'best_loss': float('inf'),
                'epochs_trained': 0,
                'checkpoint_exists': False
            }
    
    def grid_search(self, param_grid, max_experiments=None):
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ìˆ˜í–‰"""
        print("ğŸ” ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘")
        
        # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        keys = list(param_grid.keys())
        values = list(param_grid.values())
        combinations = list(itertools.product(*values))
        
        if max_experiments and len(combinations) > max_experiments:
            import random
            combinations = random.sample(combinations, max_experiments)
            print(f"ğŸ“Š {len(combinations)}ê°œ ì¡°í•©ì„ ëœë¤ ìƒ˜í”Œë§")
        
        print(f"ğŸ“Š ì´ {len(combinations)}ê°œ ì‹¤í—˜ ì˜ˆì •")
        
        for i, combination in enumerate(combinations, 1):
            # íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            params = dict(zip(keys, combination))
            experiment_name = f"exp_{i:03d}_{int(time.time())}"
            
            print(f"\n{'='*50}")
            print(f"ì‹¤í—˜ {i}/{len(combinations)}: {experiment_name}")
            print(f"íŒŒë¼ë¯¸í„°: {params}")
            
            # ì‹¤í—˜ ì„¤ì • ìƒì„±
            config_path = self.create_experiment_config(params, experiment_name)
            
            # ì‹¤í—˜ ì‹¤í–‰
            success, runtime = self.run_experiment(config_path, experiment_name)
            
            # ê²°ê³¼ ì¶”ì¶œ
            if success:
                metrics = self.extract_results(experiment_name)
            else:
                metrics = {
                    'best_loss': float('inf'),
                    'epochs_trained': 0,
                    'checkpoint_exists': False
                }
            
            # ê²°ê³¼ ì €ì¥
            result = {
                'experiment_name': experiment_name,
                'parameters': params,
                'success': success,
                'runtime': runtime,
                'metrics': metrics,
                'timestamp': datetime.now().isoformat()
            }
            
            self.results.append(result)
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            self.save_results()
            
            print(f"ê²°ê³¼: Loss={metrics['best_loss']:.4f}, "
                  f"Epochs={metrics['epochs_trained']}, "
                  f"Runtime={runtime:.1f}s")
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        results_file = self.output_dir / 'tuning_results.json'
        with open(results_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {results_file}")
    
    def print_summary(self):
        """ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.results:
            print("âŒ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n{'='*60}")
        print("ğŸ† í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*60}")
        
        # ì„±ê³µí•œ ì‹¤í—˜ë§Œ í•„í„°ë§
        successful_results = [r for r in self.results if r['success']]
        
        if not successful_results:
            print("âŒ ì„±ê³µí•œ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìµœê³  ì„±ëŠ¥ ì‹¤í—˜ ì°¾ê¸°
        best_result = min(successful_results, key=lambda x: x['metrics']['best_loss'])
        
        print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ì‹¤í—˜:")
        print(f"   ì‹¤í—˜ëª…: {best_result['experiment_name']}")
        print(f"   Loss: {best_result['metrics']['best_loss']:.4f}")
        print(f"   íŒŒë¼ë¯¸í„°:")
        for key, value in best_result['parameters'].items():
            print(f"     {key}: {value}")
        
        # ìƒìœ„ 3ê°œ ì‹¤í—˜
        top_3 = sorted(successful_results, key=lambda x: x['metrics']['best_loss'])[:3]
        
        print(f"\nğŸ† ìƒìœ„ 3ê°œ ì‹¤í—˜:")
        for i, result in enumerate(top_3, 1):
            print(f"   {i}. {result['experiment_name']} - "
                  f"Loss: {result['metrics']['best_loss']:.4f}")
        
        # ì „ì²´ í†µê³„
        losses = [r['metrics']['best_loss'] for r in successful_results 
                 if r['metrics']['best_loss'] != float('inf')]
        
        if losses:
            print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
            print(f"   ì„±ê³µí•œ ì‹¤í—˜: {len(successful_results)}/{len(self.results)}")
            print(f"   í‰ê·  Loss: {sum(losses)/len(losses):.4f}")
            print(f"   ìµœê³  Loss: {min(losses):.4f}")
            print(f"   ìµœì € Loss: {max(losses):.4f}")
        
        # ìµœì  ì„¤ì • íŒŒì¼ ìƒì„±
        best_config_path = self.output_dir / 'best_config.yaml'
        best_config = self.base_config.copy()
        
        # ìµœì  íŒŒë¼ë¯¸í„° ì ìš©
        for key_path, value in best_result['parameters'].items():
            keys = key_path.split('.')
            current = best_config
            for key in keys[:-1]:
                if key not in current:
                    current[key] = {}
                current = current[key]
            current[keys[-1]] = value
        
        best_config['experiment_name'] = 'best_tuned_model'
        
        with open(best_config_path, 'w') as f:
            yaml.dump(best_config, f, default_flow_style=False)
        
        print(f"\nğŸ’¾ ìµœì  ì„¤ì • ì €ì¥: {best_config_path}")

def load_tuning_ranges(ranges_file):
    """íŠœë‹ ë²”ìœ„ íŒŒì¼ ë¡œë“œ"""
    if ranges_file and Path(ranges_file).exists():
        with open(ranges_file, 'r') as f:
            return yaml.safe_load(f)
    else:
        # ê¸°ë³¸ íŠœë‹ ë²”ìœ„
        return {
            'training.batch_size': [16, 32, 64],
            'training.learning_rate': [0.001, 0.01, 0.02],
            'model.head.reduction_ratio': [8, 16, 32],
            'training.weight_decay': [0.0001, 0.0005, 0.001]
        }

def main():
    parser = argparse.ArgumentParser(description='í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹')
    parser.add_argument('--base_config', default='configs/model_config.yaml', 
                       help='ê¸°ë³¸ ì„¤ì • íŒŒì¼')
    parser.add_argument('--param_ranges', default=None,
                       help='íŒŒë¼ë¯¸í„° ë²”ìœ„ íŒŒì¼ (YAML)')
    parser.add_argument('--experiments', type=int, default=10,
                       help='ìµœëŒ€ ì‹¤í—˜ íšŸìˆ˜')
    parser.add_argument('--output_dir', default='experiments',
                       help='ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # íŠœë„ˆ ì´ˆê¸°í™”
    tuner = HyperparameterTuner(args.base_config, args.output_dir)
    
    # íŒŒë¼ë¯¸í„° ë²”ìœ„ ë¡œë“œ
    param_ranges = load_tuning_ranges(args.param_ranges)
    
    print("ğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ ì‹œì‘")
    print(f"ê¸°ë³¸ ì„¤ì •: {args.base_config}")
    print(f"ìµœëŒ€ ì‹¤í—˜: {args.experiments}íšŒ")
    print(f"íŒŒë¼ë¯¸í„° ë²”ìœ„: {param_ranges}")
    
    # ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
    tuner.grid_search(param_ranges, args.experiments)
    
    # ê²°ê³¼ ìš”ì•½
    tuner.print_summary()
    
    print(f"\nğŸ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {args.output_dir}/")

if __name__ == '__main__':
    main()